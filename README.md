# Function Approximator

There's a [theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem) that says that a feed-forward neural net with a single hidden layer containing a finite number of neurons can approximate any continuous function on a compact subset of **R**<sup>n</sup>. Here's a Tensorflow implementation of just such a Universal Approximator.

![Sine](https://github.com/neal-o-r/function_approx/blob/master/sin.png)
![Cubic](https://github.com/neal-o-r/function_approx/blob/master/cubic.png)
![More Complex](https://github.com/neal-o-r/function_approx/blob/master/more_complex.png)
